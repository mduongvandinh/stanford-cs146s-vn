# ğŸ”§ HÆ¯á»šNG DáºªN CÃC Ká»¸ THUáº¬T PROMPTING NÃ‚NG CAO
## Tá»•ng há»£p tá»« Prompting Guide (promptingguide.ai)

---

# ğŸ“– Má»¤C Lá»¤C

1. [Tá»•ng quan cÃ¡c ká»¹ thuáº­t](#1-tá»•ng-quan-cÃ¡c-ká»¹-thuáº­t)
2. [Zero-shot Prompting](#2-zero-shot-prompting)
3. [Few-shot Prompting](#3-few-shot-prompting)
4. [Chain-of-Thought (CoT)](#4-chain-of-thought-cot)
5. [Self-Consistency](#5-self-consistency)
6. [Tree of Thoughts (ToT)](#6-tree-of-thoughts-tot)
7. [RAG - Retrieval Augmented Generation](#7-rag---retrieval-augmented-generation)
8. [ReAct - Reasoning + Acting](#8-react---reasoning--acting)
9. [Reflexion](#9-reflexion)
10. [So sÃ¡nh vÃ  lá»±a chá»n ká»¹ thuáº­t](#10-so-sÃ¡nh-vÃ -lá»±a-chá»n-ká»¹-thuáº­t)
11. [Tá»« Ä‘iá»ƒn Keywords](#11-tá»«-Ä‘iá»ƒn-keywords)

---

# 1. Tá»”NG QUAN CÃC Ká»¸ THUáº¬T

## ğŸ“Œ Báº£n Ä‘á»“ cÃ¡c ká»¹ thuáº­t Prompting

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CÃC Ká»¸ THUáº¬T PROMPTING                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Zero-shot  â”‚â”€â”€â”€â”€â–¶â”‚  Few-shot   â”‚â”€â”€â”€â”€â–¶â”‚    CoT      â”‚           â”‚
â”‚  â”‚ (CÆ¡ báº£n)    â”‚     â”‚ (CÃ³ vÃ­ dá»¥) â”‚     â”‚ (Suy luáº­n)  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                  â”‚                  â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                            â–¼                                    â–¼   â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                   â”‚    Self-    â”‚                     â”‚  Tree of  â”‚ â”‚
â”‚                   â”‚ Consistency â”‚                     â”‚  Thoughts â”‚ â”‚
â”‚                   â”‚ (Vote Ä‘Ã¡p Ã¡n)â”‚                    â”‚ (Äa nhÃ¡nh)â”‚ â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Ká»¸ THUáº¬T TÃCH Há»¢P CÃ”NG Cá»¤                       â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚    RAG      â”‚   ReAct     â”‚        Reflexion                â”‚   â”‚
â”‚  â”‚(+Database)  â”‚(+Tools)     â”‚    (+Self-improvement)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ Báº£ng so sÃ¡nh nhanh

| Ká»¹ thuáº­t | Äá»™ phá»©c táº¡p | Use case chÃ­nh | YÃªu cáº§u |
|----------|-------------|----------------|---------|
| Zero-shot | â­ | Task Ä‘Æ¡n giáº£n | Model máº¡nh |
| Few-shot | â­â­ | Cáº§n format cá»¥ thá»ƒ | VÃ­ dá»¥ tá»‘t |
| CoT | â­â­ | BÃ i toÃ¡n logic | Prompt suy luáº­n |
| Self-Consistency | â­â­â­ | Cáº§n Ä‘á»™ chÃ­nh xÃ¡c | Nhiá»u láº§n cháº¡y |
| ToT | â­â­â­â­ | BÃ i toÃ¡n phá»©c táº¡p | Search algorithm |
| RAG | â­â­â­ | Cáº§n data má»›i | Vector database |
| ReAct | â­â­â­â­ | Multi-step tasks | Tool access |
| Reflexion | â­â­â­â­â­ | Self-improvement | Feedback loop |

---

# 2. ZERO-SHOT PROMPTING

## ğŸ“Œ Äá»‹nh nghÄ©a

**Zero-shot = Há»i trá»±c tiáº¿p, khÃ´ng cung cáº¥p vÃ­ dá»¥**

Model dá»±a hoÃ n toÃ n vÃ o kiáº¿n thá»©c Ä‘Ã£ Ä‘Æ°á»£c train Ä‘á»ƒ hiá»ƒu vÃ  thá»±c hiá»‡n task.

---

## ğŸ“Œ CÃ¡ch hoáº¡t Ä‘á»™ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ZERO-SHOT                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚   USER: "PhÃ¢n loáº¡i sentiment:              â”‚
â”‚          'Sáº£n pháº©m tuyá»‡t vá»i!'             â”‚
â”‚          Sentiment: "                      â”‚
â”‚                    â”‚                       â”‚
â”‚                    â–¼                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚   LLM (Ä‘Ã£ train sáºµn vá»     â”‚           â”‚
â”‚   â”‚   sentiment analysis)      â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                    â”‚                       â”‚
â”‚                    â–¼                       â”‚
â”‚   OUTPUT: "Positive"                       â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ VÃ­ dá»¥ thá»±c táº¿

```
ZERO-SHOT CLASSIFICATION:

Prompt:
"PhÃ¢n loáº¡i vÄƒn báº£n sau vÃ o má»™t trong cÃ¡c danh má»¥c:
[Thá»ƒ thao, CÃ´ng nghá»‡, Giáº£i trÃ­, Kinh táº¿]

VÄƒn báº£n: 'Apple vá»«a ra máº¯t iPhone 16 vá»›i chip A18 má»›i'
Danh má»¥c: "

Output: "CÃ´ng nghá»‡"
```

## ğŸ“Œ Khi nÃ o nÃªn dÃ¹ng?

| âœ… NÃªn dÃ¹ng | âŒ KhÃ´ng nÃªn dÃ¹ng |
|-------------|-------------------|
| Task Ä‘Æ¡n giáº£n, phá»• biáº¿n | Task phá»©c táº¡p, cáº§n nhiá»u bÆ°á»›c |
| Model máº¡nh (GPT-4, Claude) | Model yáº¿u hÆ¡n |
| KhÃ´ng cáº§n format Ä‘áº·c biá»‡t | Cáº§n output format cá»¥ thá»ƒ |
| Thá»­ nghiá»‡m nhanh | Production cáº§n á»•n Ä‘á»‹nh |

## ğŸ“Œ Yáº¿u tá»‘ giÃºp Zero-shot hiá»‡u quáº£

```
1. INSTRUCTION TUNING
   â†’ Model Ä‘Æ°á»£c fine-tune Ä‘á»ƒ follow instructions

2. RLHF (Reinforcement Learning from Human Feedback)
   â†’ Model Ä‘Æ°á»£c align vá»›i mong muá»‘n cá»§a ngÆ°á»i dÃ¹ng

3. SCALE
   â†’ Model cÃ ng lá»›n, zero-shot cÃ ng tá»‘t
```

---

# 3. FEW-SHOT PROMPTING

## ğŸ“Œ Äá»‹nh nghÄ©a

**Few-shot = Cung cáº¥p K vÃ­ dá»¥ (input â†’ output) trÆ°á»›c khi há»i**

Model há»c pattern tá»« cÃ¡c vÃ­ dá»¥ vÃ  Ã¡p dá»¥ng cho input má»›i.

---

## ğŸ“Œ CÃ¡ch hoáº¡t Ä‘á»™ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEW-SHOT                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚   EXAMPLES (In-context learning):                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚ Input: "I love this!" â†’ Positive     â”‚             â”‚
â”‚   â”‚ Input: "This is bad" â†’ Negative      â”‚             â”‚
â”‚   â”‚ Input: "It's okay" â†’ Neutral         â”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                      â”‚                                 â”‚
â”‚                      â–¼ LLM há»c pattern                 â”‚
â”‚                                                        â”‚
â”‚   NEW INPUT: "Amazing product!"                        â”‚
â”‚                      â”‚                                 â”‚
â”‚                      â–¼                                 â”‚
â”‚   OUTPUT: "Positive"                                   â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ VÃ­ dá»¥ thá»±c táº¿

```
FEW-SHOT TRANSLATION (Tiáº¿ng lÃ³ng â†’ Tiáº¿ng chuáº©n):

Prompt:
"Dá»‹ch tiáº¿ng lÃ³ng sang tiáº¿ng Viá»‡t chuáº©n:

'Chill Ä‘i bro' â†’ 'ThÆ° giÃ£n Ä‘i báº¡n'
'Flex quÃ¡ trá»i' â†’ 'Khoe khoang quÃ¡ má»©c'
'Vibe nÃ y Ä‘á»‰nh' â†’ 'KhÃ´ng khÃ­ nÃ y tuyá»‡t vá»i'

'Deadline gáº¥p quÃ¡, stress vl' â†’ "

Output: "'Háº¡n chÃ³t gáº¥p quÃ¡, cÄƒng tháº³ng láº¯m'"
```

## ğŸ“Œ Tips chá»n vÃ­ dá»¥ tá»‘t

```
âœ… ÄA Dáº NG:
   - Cover nhiá»u trÆ°á»ng há»£p khÃ¡c nhau
   - Bao gá»“m cáº£ edge cases

âœ… Äáº I DIá»†N:
   - TÆ°Æ¡ng tá»± vá»›i task thá»±c táº¿
   - CÃ¹ng domain/ngá»¯ cáº£nh

âœ… RÃ• RÃ€NG:
   - Format nháº¥t quÃ¡n
   - Input â†’ Output rÃµ rÃ ng

âš ï¸ THá»¨ Tá»° QUAN TRá»ŒNG:
   - VÃ­ dá»¥ cuá»‘i cÃ³ áº£nh hÆ°á»Ÿng lá»›n hÆ¡n (Recency Bias)
   - Thá»­ nghiá»‡m nhiá»u thá»© tá»± khÃ¡c nhau
```

## ğŸ“Œ 3 Bias cáº§n lÆ°u Ã½

| Bias | MÃ´ táº£ | CÃ¡ch kháº¯c phá»¥c |
|------|-------|----------------|
| **Majority Label** | Náº¿u cÃ³ nhiá»u vÃ­ dá»¥ positive, model thiÃªn vá» positive | CÃ¢n báº±ng sá»‘ lÆ°á»£ng má»—i label |
| **Recency** | Model cÃ³ xu hÆ°á»›ng copy label cá»§a vÃ­ dá»¥ cuá»‘i | Randomize thá»© tá»± |
| **Common Token** | Æ¯u tiÃªn tá»« xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn | DÃ¹ng calibration |

---

# 4. CHAIN-OF-THOUGHT (CoT)

## ğŸ“Œ Äá»‹nh nghÄ©a

**Chain-of-Thought = YÃªu cáº§u model giáº£i thÃ­ch tá»«ng bÆ°á»›c suy luáº­n**

Thay vÃ¬ Ä‘Æ°a Ä‘Ã¡p Ã¡n trá»±c tiáº¿p, model "nghÄ© to" vÃ  show reasoning.

---

## ğŸ“Œ So sÃ¡nh vá»›i/khÃ´ng vá»›i CoT

```
âŒ KHÃ”NG CÃ“ CoT:

Prompt: "Roger cÃ³ 5 quáº£ bÃ³ng. Mua thÃªm 2 há»™p, má»—i há»™p 3 quáº£.
         Há»i cÃ³ bao nhiÃªu quáº£?"
Output: "11" (cÃ³ thá»ƒ sai vá»›i bÃ i khÃ³ hÆ¡n)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… CÃ“ CoT:

Prompt: "Roger cÃ³ 5 quáº£ bÃ³ng. Mua thÃªm 2 há»™p, má»—i há»™p 3 quáº£.
         Há»i cÃ³ bao nhiÃªu quáº£? HÃ£y suy luáº­n tá»«ng bÆ°á»›c."

Output:
"BÆ°á»›c 1: Roger ban Ä‘áº§u cÃ³ 5 quáº£ bÃ³ng.
 BÆ°á»›c 2: Mua thÃªm 2 há»™p Ã— 3 quáº£/há»™p = 6 quáº£.
 BÆ°á»›c 3: Tá»•ng = 5 + 6 = 11 quáº£.

 ÄÃ¡p Ã¡n: 11 quáº£ bÃ³ng."
```

## ğŸ“Œ Zero-shot CoT - Thá»§ thuáº­t Ä‘Æ¡n giáº£n nhÆ°ng máº¡nh

```
ğŸª„ CHá»ˆ Cáº¦N THÃŠM Má»˜T CÃ‚U:

"Let's think step by step"
hoáº·c
"HÃ£y suy nghÄ© tá»«ng bÆ°á»›c"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VÃ Dá»¤:

Prompt: "Trong phÃ²ng cÃ³ 3 káº» giáº¿t ngÆ°á»i vÃ  5 ngÆ°á»i bÃ¬nh thÆ°á»ng.
         Ai Ä‘Ã³ vÃ o phÃ²ng vÃ  giáº¿t 1 káº» giáº¿t ngÆ°á»i.
         Há»i cÃ²n bao nhiÃªu ngÆ°á»i trong phÃ²ng?

         Let's think step by step."

Output:
"BÆ°á»›c 1: Ban Ä‘áº§u cÃ³ 3 + 5 = 8 ngÆ°á»i.
 BÆ°á»›c 2: Ai Ä‘Ã³ vÃ o â†’ 9 ngÆ°á»i.
 BÆ°á»›c 3: Giáº¿t 1 ngÆ°á»i â†’ 9 - 1 = 8 ngÆ°á»i.
 (XÃ¡c cháº¿t váº«n trong phÃ²ng, ngÆ°á»i má»›i váº«n á»Ÿ láº¡i)

 ÄÃ¡p Ã¡n: 8 ngÆ°á»i sá»‘ng + 1 xÃ¡c = 9"
```

## ğŸ“Œ Khi nÃ o CoT hiá»‡u quáº£?

```
âœ… Ráº¤T HIá»†U QUáº¢:
   - BÃ i toÃ¡n sá»‘ há»c
   - Logic puzzles
   - Multi-step reasoning
   - CÃ¢u há»i phÃ¢n tÃ­ch

âŒ KHÃ”NG Cáº¦N THIáº¾T:
   - Task Ä‘Æ¡n giáº£n (phÃ¢n loáº¡i cÆ¡ báº£n)
   - Translation
   - Text generation Ä‘Æ¡n thuáº§n
```

---

# 5. SELF-CONSISTENCY

## ğŸ“Œ Äá»‹nh nghÄ©a

**Self-Consistency = Cháº¡y nhiá»u láº§n, chá»n Ä‘Ã¡p Ã¡n xuáº¥t hiá»‡n nhiá»u nháº¥t**

Thay vÃ¬ tin vÃ o 1 láº§n cháº¡y, ta táº¡o nhiá»u "Ä‘Æ°á»ng suy luáº­n" vÃ  vote.

---

## ğŸ“Œ CÃ¡ch hoáº¡t Ä‘á»™ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SELF-CONSISTENCY                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚   Prompt â”€â”€â”¬â”€â”€â–¶ Láº§n 1: Suy luáº­n A â†’ ÄÃ¡p Ã¡n: 67         â”‚
â”‚            â”‚                                            â”‚
â”‚            â”œâ”€â”€â–¶ Láº§n 2: Suy luáº­n B â†’ ÄÃ¡p Ã¡n: 67         â”‚
â”‚            â”‚                                            â”‚
â”‚            â”œâ”€â”€â–¶ Láº§n 3: Suy luáº­n C â†’ ÄÃ¡p Ã¡n: 35         â”‚
â”‚            â”‚                                            â”‚
â”‚            â”œâ”€â”€â–¶ Láº§n 4: Suy luáº­n D â†’ ÄÃ¡p Ã¡n: 67         â”‚
â”‚            â”‚                                            â”‚
â”‚            â””â”€â”€â–¶ Láº§n 5: Suy luáº­n E â†’ ÄÃ¡p Ã¡n: 67         â”‚
â”‚                                                         â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â”‚
â”‚   MAJORITY VOTING:                                      â”‚
â”‚   â€¢ 67 xuáº¥t hiá»‡n: 4 láº§n (80%)                          â”‚
â”‚   â€¢ 35 xuáº¥t hiá»‡n: 1 láº§n (20%)                          â”‚
â”‚                                                         â”‚
â”‚   â†’ ÄÃ¡p Ã¡n cuá»‘i cÃ¹ng: 67 âœ…                             â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ VÃ­ dá»¥ thá»±c táº¿

```
BÃ€I TOÃN: "Khi tÃ´i 6 tuá»•i, em gÃ¡i tÃ´i báº±ng ná»­a tuá»•i tÃ´i.
           BÃ¢y giá» tÃ´i 70 tuá»•i. Em gÃ¡i tÃ´i bao nhiÃªu tuá»•i?"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CHáº Y 1 Láº¦N (cÃ³ thá»ƒ sai):
"Ná»­a cá»§a 70 = 35 tuá»•i" âŒ

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SELF-CONSISTENCY (5 láº§n):

Láº§n 1: "6/2 = 3 tuá»•i khi Ä‘Ã³ â†’ 70 - 6 + 3 = 67" âœ…
Láº§n 2: "Em kÃ©m 3 tuá»•i â†’ 70 - 3 = 67" âœ…
Láº§n 3: "Ná»­a cá»§a 70 = 35" âŒ
Láº§n 4: "Hiá»‡u sá»‘ tuá»•i = 3 â†’ 67 tuá»•i" âœ…
Láº§n 5: "Khoáº£ng cÃ¡ch 3 nÄƒm â†’ 67" âœ…

Vote: 67 (4/5) â†’ ÄÃ¡p Ã¡n: 67 âœ…
```

## ğŸ“Œ CÃ i Ä‘áº·t

```python
# Pseudo-code cho Self-Consistency

def self_consistency(prompt, n_samples=5, temperature=0.7):
    answers = []

    for i in range(n_samples):
        # Cháº¡y vá»›i temperature > 0 Ä‘á»ƒ cÃ³ diversity
        response = llm.generate(prompt, temperature=temperature)
        answer = extract_answer(response)
        answers.append(answer)

    # Majority voting
    final_answer = most_common(answers)
    return final_answer
```

---

# 6. TREE OF THOUGHTS (ToT)

## ğŸ“Œ Äá»‹nh nghÄ©a

**Tree of Thoughts = KhÃ¡m phÃ¡ nhiá»u Ä‘Æ°á»ng suy luáº­n song song**

Thay vÃ¬ 1 chain (CoT), ta cÃ³ nhiá»u branches nhÆ° cÃ¢y, vá»›i kháº£ nÄƒng backtrack.

---

## ğŸ“Œ So sÃ¡nh CoT vs ToT

```
CHAIN-OF-THOUGHT (Linear):

    Start â†’ Step 1 â†’ Step 2 â†’ Step 3 â†’ Answer
    (Náº¿u sai á»Ÿ Step 2, cáº£ chain sai)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TREE OF THOUGHTS (Branching):

                        â”Œâ†’ Step 2a â†’ Step 3a â†’ Answer A âœ…
    Start â†’ Step 1 â”€â”€â”€â”€â”€â”¤
                        â”œâ†’ Step 2b â†’ Step 3b â†’ Answer B âŒ
                        â”‚                      (backtrack)
                        â””â†’ Step 2c â†’ Step 3c â†’ Answer C âœ…

    (Evaluate vÃ  chá»n paths tá»‘t nháº¥t)
```

## ğŸ“Œ CÃ¡ch hoáº¡t Ä‘á»™ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TREE OF THOUGHTS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. DECOMPOSE: Chia bÃ i toÃ¡n thÃ nh cÃ¡c "thought" nhá»       â”‚
â”‚                                                             â”‚
â”‚  2. GENERATE: Táº¡o nhiá»u candidates cho má»—i step            â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚     â”‚ Step 1: Candidate A, B, C, D, E        â”‚               â”‚
â”‚     â”‚ â†’ ÄÃ¡nh giÃ¡: A=maybe, B=sure, C=impossibleâ”‚             â”‚
â”‚     â”‚ â†’ Giá»¯ láº¡i top K (B, A)                 â”‚               â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                             â”‚
â”‚  3. EVALUATE: LLM tá»± Ä‘Ã¡nh giÃ¡ tá»«ng candidate               â”‚
â”‚     - "sure" (cháº¯c cháº¯n Ä‘Ãºng)                               â”‚
â”‚     - "maybe" (cÃ³ thá»ƒ)                                      â”‚
â”‚     - "impossible" (sai rá»“i, bá»)                            â”‚
â”‚                                                             â”‚
â”‚  4. SEARCH: BFS hoáº·c DFS Ä‘á»ƒ explore tree                   â”‚
â”‚     - Breadth-First: Explore rá»™ng trÆ°á»›c                     â”‚
â”‚     - Depth-First: Äi sÃ¢u trÆ°á»›c, backtrack náº¿u cáº§n          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ VÃ­ dá»¥: Game of 24

```
BÃ€I TOÃN: DÃ¹ng 4 sá»‘ [4, 5, 6, 10] vÃ  +, -, Ã—, Ã· Ä‘á»ƒ Ä‘Æ°á»£c 24

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ToT APPROACH:

Step 1 - Thá»­ cÃ¡c phÃ©p tÃ­nh Ä‘áº§u:
â”œâ”€â”€ 4 + 5 = 9       (maybe)
â”œâ”€â”€ 5 Ã— 6 = 30      (maybe)
â”œâ”€â”€ 10 - 4 = 6      (sure - cÃ³ thá»ƒ vá» 24)
â””â”€â”€ 4 Ã— 6 = 24      (sure! - cÃ²n 5, 10 pháº£i = 0 hoáº·c Ã—1)

Step 2 - Tá»« "4 Ã— 6 = 24":
â”œâ”€â”€ 24 + (10 - 5) = 29  (impossible)
â”œâ”€â”€ 24 Ã— (10 - 5)/5 = ... (maybe)
â””â”€â”€ 24 + 5 - 10 = 19 (impossible)

... continue exploring ...

Final: (10 - 4) Ã— (6 - 2) = 24 âœ…
       NhÆ°ng khÃ´ng cÃ³ 2! Thá»­ láº¡i...

       5 Ã— (10 - 6) + 4 = 5 Ã— 4 + 4 = 24 âœ…
```

## ğŸ“Œ Simplified ToT Prompt

```
"Imagine three different experts are answering this question.
All experts will write down 1 step of their thinking,
then share it with the group.
Then all experts will go on to the next step, etc.
If any expert realizes they're wrong at any point, they leave.
The question is..."
```

---

# 7. RAG - RETRIEVAL AUGMENTED GENERATION

## ğŸ“Œ Äá»‹nh nghÄ©a

**RAG = Káº¿t há»£p TÃŒM KIáº¾M + Táº O VÄ‚N Báº¢N**

Thay vÃ¬ chá»‰ dá»±a vÃ o kiáº¿n thá»©c Ä‘Ã£ train, model tÃ¬m kiáº¿m thÃ´ng tin tá»« database/documents trÆ°á»›c khi tráº£ lá»i.

---

## ğŸ“Œ Táº¡i sao cáº§n RAG?

```
Váº¤N Äá»€ Cá»¦A LLM THUáº¦N:

âŒ Knowledge Cutoff: KhÃ´ng biáº¿t thÃ´ng tin sau ngÃ y train
âŒ Hallucination: CÃ³ thá»ƒ bá»‹a thÃ´ng tin
âŒ No Source: KhÃ´ng thá»ƒ cite nguá»“n
âŒ Generic: KhÃ´ng cÃ³ domain-specific knowledge

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

RAG GIáº¢I QUYáº¾T:

âœ… Real-time: Truy cáº­p data má»›i nháº¥t
âœ… Factual: Dá»±a trÃªn documents tháº­t
âœ… Verifiable: CÃ³ thá»ƒ check nguá»“n
âœ… Specialized: ThÃªm knowledge cá»§a cÃ´ng ty/domain
```

## ğŸ“Œ Kiáº¿n trÃºc RAG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAG PIPELINE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  User   â”‚â”€â”€â”€â”€â–¶â”‚   Retriever   â”‚â”€â”€â”€â”€â–¶â”‚    Generator    â”‚    â”‚
â”‚   â”‚ Query   â”‚     â”‚ (TÃ¬m kiáº¿m)    â”‚     â”‚   (Táº¡o vÄƒn báº£n) â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                       â”‚             â”‚
â”‚                           â–¼                       â”‚             â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚             â”‚
â”‚               â”‚  Vector Database  â”‚               â”‚             â”‚
â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”  â”‚               â”‚             â”‚
â”‚               â”‚  â”‚Doc 1â”‚ â”‚Doc 2â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚               â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â”‚  (Top K docs)               â”‚
â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”  â”‚                             â”‚
â”‚               â”‚  â”‚Doc 3â”‚ â”‚Doc 4â”‚  â”‚                             â”‚
â”‚               â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â”‚                             â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                 â”‚
â”‚   OUTPUT: Answer + Citations                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ VÃ­ dá»¥ thá»±c táº¿

```
KHÃ”NG CÃ“ RAG:

User: "GiÃ¡ cá»• phiáº¿u Apple hÃ´m nay?"
LLM: "TÃ´i khÃ´ng cÃ³ thÃ´ng tin real-time vá» giÃ¡ cá»• phiáº¿u."

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CÃ“ RAG:

User: "GiÃ¡ cá»• phiáº¿u Apple hÃ´m nay?"

Step 1 - Retrieve:
â†’ Query finance API/database
â†’ Láº¥y: "AAPL: $178.50, +2.3%, Dec 19 2024"

Step 2 - Generate:
Prompt to LLM:
"Dá»±a trÃªn data sau, tráº£ lá»i cÃ¢u há»i:
[Context: AAPL: $178.50, +2.3%, Dec 19 2024]
Question: GiÃ¡ cá»• phiáº¿u Apple hÃ´m nay?"

LLM: "GiÃ¡ cá»• phiáº¿u Apple (AAPL) hÃ´m nay lÃ  $178.50,
      tÄƒng 2.3% so vá»›i hÃ´m qua. (Nguá»“n: Dec 19 2024)"
```

## ğŸ“Œ CÃ¡c bÆ°á»›c implement RAG

```
1. DOCUMENT PROCESSING
   - Chia documents thÃ nh chunks
   - Má»—i chunk ~500-1000 tokens

2. EMBEDDING
   - Chuyá»ƒn chunks thÃ nh vectors
   - DÃ¹ng embedding model (OpenAI, Cohere, ...)

3. INDEXING
   - LÆ°u vectors vÃ o Vector DB
   - (Pinecone, Weaviate, ChromaDB, ...)

4. RETRIEVAL
   - Embed user query
   - TÃ¬m top-K similar chunks

5. GENERATION
   - Concat context + query
   - LLM generate answer
```

---

# 8. ReAct - REASONING + ACTING

## ğŸ“Œ Äá»‹nh nghÄ©a

**ReAct = Káº¿t há»£p SUY LUáº¬N + HÃ€NH Äá»˜NG trong vÃ²ng láº·p**

Model vá»«a "nghÄ©" (reasoning) vá»«a "lÃ m" (acting), dÃ¹ng tools bÃªn ngoÃ i.

---

## ğŸ“Œ CÃ¡ch hoáº¡t Ä‘á»™ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ReAct LOOP                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                      â”‚  â”‚
â”‚   â”‚  THOUGHT: "TÃ´i cáº§n tÃ¬m thÃ´ng tin vá» X"              â”‚  â”‚
â”‚   â”‚      â”‚                                               â”‚  â”‚
â”‚   â”‚      â–¼                                               â”‚  â”‚
â”‚   â”‚  ACTION: Search("X")                                 â”‚  â”‚
â”‚   â”‚      â”‚                                               â”‚  â”‚
â”‚   â”‚      â–¼                                               â”‚  â”‚
â”‚   â”‚  OBSERVATION: "Káº¿t quáº£ tÃ¬m kiáº¿m: ..."               â”‚  â”‚
â”‚   â”‚      â”‚                                               â”‚  â”‚
â”‚   â”‚      â–¼                                               â”‚  â”‚
â”‚   â”‚  THOUGHT: "Tá»« káº¿t quáº£, tÃ´i tháº¥y Y, cáº§n tÃ¬m thÃªm Z"  â”‚  â”‚
â”‚   â”‚      â”‚                                               â”‚  â”‚
â”‚   â”‚      â–¼                                               â”‚  â”‚
â”‚   â”‚  ACTION: Lookup("Z")                                 â”‚  â”‚
â”‚   â”‚      â”‚                                               â”‚  â”‚
â”‚   â”‚      â–¼                                               â”‚  â”‚
â”‚   â”‚  OBSERVATION: "Z lÃ  ..."                            â”‚  â”‚
â”‚   â”‚      â”‚                                               â”‚  â”‚
â”‚   â”‚      â–¼                                               â”‚  â”‚
â”‚   â”‚  THOUGHT: "BÃ¢y giá» tÃ´i cÃ³ Ä‘á»§ info Ä‘á»ƒ tráº£ lá»i"       â”‚  â”‚
â”‚   â”‚      â”‚                                               â”‚  â”‚
â”‚   â”‚      â–¼                                               â”‚  â”‚
â”‚   â”‚  ACTION: Finish("CÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng")            â”‚  â”‚
â”‚   â”‚                                                      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ VÃ­ dá»¥: HotpotQA

```
QUESTION: "Thá»§ Ä‘Ã´ cá»§a quá»‘c gia cÃ³ diá»‡n tÃ­ch lá»›n nháº¥t
           chÃ¢u Ã náº±m á»Ÿ bá» sÃ´ng nÃ o?"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Thought 1: TÃ´i cáº§n tÃ¬m quá»‘c gia cÃ³ diá»‡n tÃ­ch lá»›n nháº¥t chÃ¢u Ã
Action 1: Search["largest country in Asia by area"]
Observation 1: Russia is the largest country in Asia...

Thought 2: NhÆ°ng pháº§n lá»›n Russia á»Ÿ chÃ¢u Ã‚u. Náº¿u chá»‰ tÃ­nh
           chÃ¢u Ã, China cÃ³ thá»ƒ lá»›n nháº¥t. TÃ´i cáº§n verify.
Action 2: Search["largest country entirely in Asia"]
Observation 2: China is the largest country located
               entirely within Asia...

Thought 3: Váº­y lÃ  China. Thá»§ Ä‘Ã´ China lÃ  Beijing.
           TÃ´i cáº§n tÃ¬m Beijing náº±m bá» sÃ´ng nÃ o.
Action 3: Search["Beijing river"]
Observation 3: Beijing is located on the Yongding River...

Thought 4: TÃ´i Ä‘Ã£ cÃ³ Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i.
Action 4: Finish["SÃ´ng Yongding (VÄ©nh Äá»‹nh)"]
```

## ğŸ“Œ So sÃ¡nh ReAct vs CoT vs Action-only

| Approach | Reasoning | Actions | Káº¿t quáº£ |
|----------|-----------|---------|---------|
| CoT only | âœ… | âŒ | CÃ³ thá»ƒ sai do thiáº¿u info |
| Action only | âŒ | âœ… | Thiáº¿u direction, khÃ´ng hiá»‡u quáº£ |
| **ReAct** | âœ… | âœ… | **Tá»‘t nháº¥t - cÃ³ cáº£ hai** |

---

# 9. REFLEXION

## ğŸ“Œ Äá»‹nh nghÄ©a

**Reflexion = Agent tá»± PHáº¢N CHIáº¾U vÃ  Cáº¢I THIá»†N qua tá»«ng láº§n thá»­**

Thay vÃ¬ training láº¡i model, ta dÃ¹ng "verbal reinforcement" - feedback báº±ng ngÃ´n ngá»¯.

---

## ğŸ“Œ 3 ThÃ nh pháº§n chÃ­nh

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REFLEXION FRAMEWORK                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚   ACTOR     â”‚ â†â”€â”€ Táº¡o actions dá»±a trÃªn observations     â”‚
â”‚  â”‚  (Agent)    â”‚      DÃ¹ng CoT + ReAct                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼ trajectories                                      â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  EVALUATOR  â”‚ â†â”€â”€ Cho Ä‘iá»ƒm output cá»§a Actor              â”‚
â”‚  â”‚  (Scorer)   â”‚      Reward signal (0-1)                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼ feedback                                          â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚        SELF-REFLECTION              â”‚                    â”‚
â”‚  â”‚  (Verbal Reinforcement)             â”‚                    â”‚
â”‚  â”‚                                     â”‚                    â”‚
â”‚  â”‚  "Láº§n trÆ°á»›c tÃ´i sai vÃ¬...          â”‚                    â”‚
â”‚  â”‚   Láº§n sau tÃ´i sáº½..."               â”‚                    â”‚
â”‚  â”‚                                     â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                 â”‚                                           â”‚
â”‚                 â–¼ memory update                             â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚   MEMORY    â”‚ â†â”€â”€ LÆ°u trá»¯ reflections                   â”‚
â”‚  â”‚ (Long-term) â”‚      cho attempts sau                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ VÃ­ dá»¥: Code Generation

```
TASK: Viáº¿t function tÃ¬m sá»‘ nguyÃªn tá»‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ATTEMPT 1:
def is_prime(n):
    for i in range(2, n):
        if n % i == 0:
            return False
    return True

Evaluator: FAIL (is_prime(1) = True, wrong!)

Self-Reflection:
"TÃ´i quÃªn xá»­ lÃ½ edge case n <= 1.
 Nhá»¯ng sá»‘ nÃ y khÃ´ng pháº£i sá»‘ nguyÃªn tá»‘.
 Láº§n sau cáº§n check Ä‘iá»u kiá»‡n Ä‘áº§u tiÃªn."

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ATTEMPT 2 (with memory):
def is_prime(n):
    if n <= 1:  # Learned from reflection
        return False
    for i in range(2, n):
        if n % i == 0:
            return False
    return True

Evaluator: FAIL (is_prime(4) takes too long for large n)

Self-Reflection:
"Function Ä‘Ãºng nhÆ°ng cháº­m vá»›i sá»‘ lá»›n.
 Chá»‰ cáº§n check Ä‘áº¿n sqrt(n) lÃ  Ä‘á»§."

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ATTEMPT 3 (with accumulated memory):
def is_prime(n):
    if n <= 1:
        return False
    if n <= 3:
        return True
    if n % 2 == 0:
        return False
    for i in range(3, int(n**0.5) + 1, 2):
        if n % i == 0:
            return False
    return True

Evaluator: PASS âœ…
```

## ğŸ“Œ Khi nÃ o dÃ¹ng Reflexion?

```
âœ… PHÃ™ Há»¢P:
   - Tasks cÃ³ thá»ƒ verify (coding, QA)
   - Cáº§n nhiá»u attempts Ä‘á»ƒ hoÃ n thiá»‡n
   - Muá»‘n agent tá»± há»c tá»« mistakes

âŒ KHÃ”NG PHÃ™ Há»¢P:
   - Tasks khÃ´ng cÃ³ clear feedback
   - One-shot tasks (khÃ´ng cÃ³ cÆ¡ há»™i retry)
   - Khi cáº§n response real-time
```

---

# 10. SO SÃNH VÃ€ Lá»°A CHá»ŒN Ká»¸ THUáº¬T

## ğŸ“Œ Decision Tree

```
                          START
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Task Ä‘Æ¡n giáº£n? â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       Yes  â”‚   No
                       â”‚    â”‚    â”‚
                       â–¼    â”‚    â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Zero-shot â”‚ â”‚  â”‚ Cáº§n reasoning?â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚     Yes  â”‚   No
                            â”‚     â”‚    â”‚    â”‚
                            â”‚     â–¼    â”‚    â–¼
                            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  â”‚  CoT    â”‚ â”‚ Cáº§n format    â”‚
                            â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚ cá»¥ thá»ƒ?       â”‚
                            â”‚       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚       â–¼         Yes  â”‚   No
                            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
                            â”‚  â”‚ Cáº§n Ä‘á»™ chÃ­nhâ”‚     â–¼    â–¼
                            â”‚  â”‚ xÃ¡c cao?    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                            â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚Few-shotâ”‚â”‚
                            â”‚    Yes  â”‚   No   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                            â”‚    â”‚    â”‚    â”‚             â”‚
                            â”‚    â–¼    â–¼    â”‚             â”‚
                            â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚             â”‚
                            â”‚ â”‚   Self-  â”‚ â”‚             â”‚
                            â”‚ â”‚Consistencyâ”‚ â”‚             â”‚
                            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚             â”‚
                            â”‚              â”‚             â”‚
                            â–¼              â–¼             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        Cáº¦N EXTERNAL DATA/TOOLS?       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                Yes  â”‚   No
                                â”‚    â”‚    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                 â”‚
                    â–¼                                 â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    Done with
           â”‚ Data má»›i?   â”‚                    above technique
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
             Yes  â”‚   No
             â”‚    â”‚    â”‚
             â–¼    â–¼    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ RAG  â”‚ â”‚  ReAct   â”‚
        â””â”€â”€â”€â”€â”€â”€â”˜ â”‚(+tools)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Œ Báº£ng tá»•ng há»£p cuá»‘i cÃ¹ng

| Ká»¹ thuáº­t | Äá»™ khÃ³ | Chi phÃ­ | Khi nÃ o dÃ¹ng |
|----------|--------|---------|--------------|
| **Zero-shot** | Dá»… | Tháº¥p | Thá»­ Ä‘áº§u tiÃªn, task Ä‘Æ¡n giáº£n |
| **Few-shot** | Dá»… | Tháº¥p | Cáº§n format output cá»¥ thá»ƒ |
| **CoT** | Trung bÃ¬nh | Tháº¥p | BÃ i toÃ¡n logic, math |
| **Self-Consistency** | Trung bÃ¬nh | Cao (nhiá»u calls) | Cáº§n accuracy cao |
| **ToT** | KhÃ³ | Ráº¥t cao | Planning, puzzles phá»©c táº¡p |
| **RAG** | KhÃ³ | Trung bÃ¬nh | Cáº§n data cáº­p nháº­t/domain |
| **ReAct** | KhÃ³ | Trung bÃ¬nh | Multi-step vá»›i tools |
| **Reflexion** | Ráº¥t khÃ³ | Cao | Agent tá»± cáº£i thiá»‡n |

---

# 11. Tá»ª ÄIá»‚N KEYWORDS

## A-F

| Keyword | NghÄ©a | Giáº£i thÃ­ch |
|---------|-------|------------|
| **Action** | HÃ nh Ä‘á»™ng | BÆ°á»›c thá»±c thi trong ReAct (search, lookup, finish) |
| **Backtracking** | Quay lui | Kháº£ nÄƒng thá»­ Ä‘Æ°á»ng khÃ¡c trong ToT |
| **BFS/DFS** | Breadth/Depth First Search | Thuáº­t toÃ¡n duyá»‡t tree trong ToT |
| **Chain-of-Thought** | Chuá»—i suy nghÄ© | Ká»¹ thuáº­t yÃªu cáº§u model giáº£i thÃ­ch tá»«ng bÆ°á»›c |
| **Chunk** | Máº£nh | Pháº§n nhá» cá»§a document trong RAG |
| **Embedding** | NhÃºng | Chuyá»ƒn text thÃ nh vector sá»‘ |
| **Few-shot** | VÃ i vÃ­ dá»¥ | Cung cáº¥p K vÃ­ dá»¥ trong prompt |

## G-R

| Keyword | NghÄ©a | Giáº£i thÃ­ch |
|---------|-------|------------|
| **Generator** | Bá»™ sinh | Pháº§n táº¡o text trong RAG |
| **In-context Learning** | Há»c trong ngá»¯ cáº£nh | Model há»c tá»« examples trong prompt |
| **Majority Voting** | Báº§u chá»n Ä‘a sá»‘ | Chá»n Ä‘Ã¡p Ã¡n phá»• biáº¿n nháº¥t |
| **Observation** | Quan sÃ¡t | Káº¿t quáº£ tá»« action trong ReAct |
| **RAG** | Retrieval Augmented Generation | Káº¿t há»£p tÃ¬m kiáº¿m + sinh text |
| **ReAct** | Reasoning + Acting | Káº¿t há»£p suy luáº­n vÃ  hÃ nh Ä‘á»™ng |
| **Reflexion** | Pháº£n chiáº¿u | Agent tá»± Ä‘Ã¡nh giÃ¡ vÃ  cáº£i thiá»‡n |
| **Retriever** | Bá»™ tÃ¬m kiáº¿m | Pháº§n tÃ¬m documents trong RAG |

## S-Z

| Keyword | NghÄ©a | Giáº£i thÃ­ch |
|---------|-------|------------|
| **Self-Consistency** | Tá»± nháº¥t quÃ¡n | Cháº¡y nhiá»u láº§n, vote Ä‘Ã¡p Ã¡n |
| **Temperature** | Nhiá»‡t Ä‘á»™ | Tham sá»‘ Ä‘iá»u chá»‰nh randomness |
| **Thought** | Suy nghÄ© | BÆ°á»›c reasoning trong ReAct/ToT |
| **ToT** | Tree of Thoughts | KhÃ¡m phÃ¡ nhiá»u Ä‘Æ°á»ng suy luáº­n |
| **Vector Database** | CSDL vector | LÆ°u trá»¯ embeddings cho RAG |
| **Zero-shot** | KhÃ´ng vÃ­ dá»¥ | Há»i trá»±c tiáº¿p khÃ´ng cáº§n demo |

---

# ğŸ“š TÃ€I NGUYÃŠN THAM KHáº¢O

## Papers gá»‘c

- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903) - Wei et al. 2022
- [Self-Consistency](https://arxiv.org/abs/2203.11171) - Wang et al. 2022
- [Tree of Thoughts](https://arxiv.org/abs/2305.10601) - Yao et al. 2023
- [RAG](https://arxiv.org/abs/2005.11401) - Lewis et al. 2020
- [ReAct](https://arxiv.org/abs/2210.03629) - Yao et al. 2022
- [Reflexion](https://arxiv.org/abs/2303.11366) - Shinn et al. 2023

## Website

- [Prompting Guide](https://www.promptingguide.ai/) - Tá»•ng há»£p Ä‘áº§y Ä‘á»§ nháº¥t
- [Learn Prompting](https://learnprompting.org/) - Course miá»…n phÃ­

---

*TÃ i liá»‡u tá»•ng há»£p cÃ¡c ká»¹ thuáº­t Prompting nÃ¢ng cao tá»« promptingguide.ai*
