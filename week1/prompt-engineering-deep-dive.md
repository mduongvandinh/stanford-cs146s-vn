# üéØ H∆Ø·ªöNG D·∫™N HI·ªÇU VIDEO "AI PROMPT ENGINEERING: A DEEP DIVE"
## Bu·ªïi th·∫£o lu·∫≠n b√†n tr√≤n t·ª´ Anthropic (c√¥ng ty t·∫°o ra Claude)

**Link video:** https://www.youtube.com/watch?v=T9aRN5JkmL8

---

# üìñ M·ª§C L·ª§C

1. [Gi·ªõi thi·ªáu v·ªÅ video v√† di·ªÖn gi·∫£](#1-gi·ªõi-thi·ªáu-v·ªÅ-video-v√†-di·ªÖn-gi·∫£)
2. [Prompt Engineering l√† g√¨?](#2-prompt-engineering-l√†-g√¨)
3. [ƒêi·ªÅu g√¨ l√†m n√™n m·ªôt Prompt Engineer gi·ªèi?](#3-ƒëi·ªÅu-g√¨-l√†m-n√™n-m·ªôt-prompt-engineer-gi·ªèi)
4. [C√°c k·ªπ thu·∫≠t Prompting quan tr·ªçng](#4-c√°c-k·ªπ-thu·∫≠t-prompting-quan-tr·ªçng)
5. [Nh·ªØng sai l·∫ßm ph·ªï bi·∫øn c·∫ßn tr√°nh](#5-nh·ªØng-sai-l·∫ßm-ph·ªï-bi·∫øn-c·∫ßn-tr√°nh)
6. [Prompting cho Enterprise vs C√° nh√¢n](#6-prompting-cho-enterprise-vs-c√°-nh√¢n)
7. [T∆∞∆°ng lai c·ªßa Prompt Engineering](#7-t∆∞∆°ng-lai-c·ªßa-prompt-engineering)
8. [Tips th·ª±c h√†nh t·ª´ chuy√™n gia](#8-tips-th·ª±c-h√†nh-t·ª´-chuy√™n-gia)
9. [T·ª´ ƒëi·ªÉn thu·∫≠t ng·ªØ](#9-t·ª´-ƒëi·ªÉn-thu·∫≠t-ng·ªØ)

---

# 1. GI·ªöI THI·ªÜU V·ªÄ VIDEO V√Ä DI·ªÑN GI·∫¢

## üìå V·ªÅ video

ƒê√¢y l√† bu·ªïi th·∫£o lu·∫≠n b√†n tr√≤n (roundtable) c·ªßa **Anthropic** - c√¥ng ty t·∫°o ra Claude. Video d√†i kho·∫£ng 1 ti·∫øng 16 ph√∫t, t·∫≠p trung ho√†n to√†n v√†o ch·ªß ƒë·ªÅ **Prompt Engineering**.

## üìå C√°c di·ªÖn gi·∫£

| T√™n | Vai tr√≤ | Chuy√™n m√¥n |
|-----|---------|------------|
| **Alex Albert** | Lead Developer Relations | C·ª±u Prompt Engineer, Solutions Architect |
| **David Hershey** | Customer Technical Support | L√†m vi·ªác v·ªõi kh√°ch h√†ng enterprise, finetuning |
| **Amanda Askell** | Lead Finetuning Team | Tri·∫øt h·ªçc, l√†m Claude "trung th·ª±c v√† t·ª≠ t·∫ø" |
| **Zack Witten** | Prompt Engineer | T·∫°o prompt generator, t√†i li·ªáu gi√°o d·ª•c |

**ƒêi·ªÉm ƒë·∫∑c bi·ªát:** ƒê√¢y l√† nh·ªØng ng∆∞·ªùi th·ª±c s·ª± l√†m vi·ªác v·ªõi Claude h√†ng ng√†y, kh√¥ng ph·∫£i l√Ω thuy·∫øt su√¥ng. H·ªç chia s·∫ª kinh nghi·ªám th·ª±c t·∫ø t·ª´ h√†ng ngh√¨n gi·ªù t∆∞∆°ng t√°c v·ªõi model.

---

# 2. PROMPT ENGINEERING L√Ä G√å?

## üìå ƒê·ªãnh nghƒ©a t·ª´ Zack Witten

> "Prompt engineering l√† c·ªë g·∫Øng khi·∫øn model l√†m ƒë∆∞·ª£c nh·ªØng vi·ªác, khai th√°c t·ªëi ƒëa kh·∫£ nƒÉng c·ªßa model. L√†m vi·ªác v·ªõi model ƒë·ªÉ ho√†n th√†nh nh·ªØng th·ª© m√† b·∫°n kh√¥ng th·ªÉ l√†m ƒë∆∞·ª£c n·∫øu kh√¥ng c√≥ n√≥."

## üìå B·∫£n ch·∫•t c·ªët l√µi

```
PROMPT ENGINEERING = GIAO TI·∫æP R√ï R√ÄNG + TH·ª¨ NGHI·ªÜM L·∫∂P L·∫†I
```

### Giao ti·∫øp r√µ r√†ng (Clear Communication)

- N√≥i chuy·ªán v·ªõi model **gi·ªëng nh∆∞ n√≥i chuy·ªán v·ªõi ng∆∞·ªùi**
- Hi·ªÉu "t√¢m l√Ω" c·ªßa model
- Di·ªÖn ƒë·∫°t ch√≠nh x√°c ƒëi·ªÅu b·∫°n mu·ªën

### T·∫°i sao g·ªçi l√† "Engineering"?

**Zack gi·∫£i th√≠ch:**
> "Ph·∫ßn engineering ƒë·∫øn t·ª´ qu√° tr√¨nh th·ª≠ v√† sai. M·ªôt ƒëi·ªÅu tuy·ªát v·ªùi khi n√≥i chuy·ªán v·ªõi model kh√°c v·ªõi n√≥i chuy·ªán v·ªõi ng∆∞·ªùi, l√† b·∫°n c√≥ n√∫t restart. B·∫°n c√≥ th·ªÉ quay l·∫°i t·ª´ ƒë·∫ßu, th·ª≠ nhi·ªÅu c√°ch kh√°c nhau m·ªôt c√°ch ƒë·ªôc l·∫≠p."

```
Quy tr√¨nh Engineering:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Vi·∫øt prompt ban ƒë·∫ßu                 ‚îÇ
‚îÇ           ‚Üì                             ‚îÇ
‚îÇ  2. Ch·∫°y th·ª≠ v·ªõi model                  ‚îÇ
‚îÇ           ‚Üì                             ‚îÇ
‚îÇ  3. ƒê·ªçc k·ªπ output                       ‚îÇ
‚îÇ           ‚Üì                             ‚îÇ
‚îÇ  4. Ph√¢n t√≠ch: Sai ·ªü ƒë√¢u? T·∫°i sao?      ‚îÇ
‚îÇ           ‚Üì                             ‚îÇ
‚îÇ  5. S·ª≠a prompt                          ‚îÇ
‚îÇ           ‚Üì                             ‚îÇ
‚îÇ  6. L·∫∑p l·∫°i t·ª´ b∆∞·ªõc 2                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìå Prompt nh∆∞ l√† "code b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n"

**David Hershey:**
> "T√¥i nghƒ© v·ªÅ prompts nh∆∞ c√°ch b·∫°n l·∫≠p tr√¨nh models. B·∫°n ph·∫£i nghƒ© v·ªÅ d·ªØ li·ªáu ƒë·∫øn t·ª´ ƒë√¢u, trade-offs v·ªÅ latency, version control... T·∫•t c·∫£ nh·ªØng th·ª© b·∫°n nghƒ© v·ªÅ khi l·∫≠p tr√¨nh ƒë·ªÅu √°p d·ª•ng cho prompting."

**ƒêi·ªÉm quan tr·ªçng:**
- Prompt KH√îNG ch·ªâ l√† vi·∫øt m·ªôt l·∫ßn r·ªìi xong
- C·∫ßn version control nh∆∞ code
- C·∫ßn tracking experiments
- C·∫ßn testing systematic

---

# 3. ƒêI·ªÄU G√å L√ÄM N√äN M·ªòT PROMPT ENGINEER GI·ªéI?

## üìå K·ªπ nƒÉng #1: Giao ti·∫øp r√µ r√†ng

**Amanda Askell:**
> "Kh·∫£ nƒÉng di·ªÖn ƒë·∫°t r√µ r√†ng, hi·ªÉu tasks m·ªôt c√°ch r√µ r√†ng, m√¥ t·∫£ concepts th·∫≠t t·ªët."

**L∆∞u √Ω quan tr·ªçng t·ª´ Amanda:**
> "T√¥i th·ª±c s·ª± nghƒ© r·∫±ng vi·ªác l√† m·ªôt writer gi·ªèi KH√îNG t∆∞∆°ng quan v·ªõi vi·ªác l√† prompt engineer gi·ªèi nh∆∞ m·ªçi ng∆∞·ªùi nghƒ©."

**T·∫°i sao?**
- Ng∆∞·ªùi ta nghƒ© b·∫°n vi·∫øt m·ªôt th·ª© v√† xong
- Th·ª±c t·∫ø: Trong 15 ph√∫t, Amanda c√≥ th·ªÉ g·ª≠i **h√†ng trƒÉm prompts** cho model
- ƒê√≥ l√† back and forth, back and forth li√™n t·ª•c

## üìå K·ªπ nƒÉng #2: Kh·∫£ nƒÉng l·∫∑p l·∫°i (Iteration)

```
Prompt Engineer GI·ªéi:
- Vi·∫øt prompt ‚Üí ƒê·ªçc output ‚Üí Ph√¢n t√≠ch l·ªói ‚Üí S·ª≠a ‚Üí L·∫∑p l·∫°i
- S·∫µn s√†ng th·ª≠ h√†ng trƒÉm l·∫ßn

Prompt Engineer K√âM:
- Vi·∫øt prompt ‚Üí Xem output ‚Üí "N√≥ kh√¥ng ho·∫°t ƒë·ªông" ‚Üí B·ªè cu·ªôc
```

## üìå K·ªπ nƒÉng #3: T∆∞ duy v·ªÅ Edge Cases

**Amanda Askell:**
> "N·∫øu b·∫°n c√≥ prompt s·∫Ω √°p d·ª•ng cho 400 cases, r·∫•t d·ªÖ nghƒ© v·ªÅ case ƒëi·ªÉn h√¨nh, th·∫•y n√≥ ho·∫°t ƒë·ªông, r·ªìi b·ªè qua. ƒê√¢y l√† sai l·∫ßm c·ªï ƒëi·ªÉn."

**C√°ch l√†m ƒë√∫ng:**
```
Thay v√¨:
  "Prompt ho·∫°t ƒë·ªông v·ªõi case th√¥ng th∆∞·ªùng" ‚Üí Done ‚úó

N√™n:
  "T√¨m c√°c cases B·∫§T TH∆Ø·ªúNG" ‚Üí Test v·ªõi nh·ªØng cases ƒë√≥
  
V√≠ d·ª• edge cases:
- Input r·ªóng
- Input sai format ho√†n to√†n
- Input c·ª±c d√†i
- Input c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát
- Input m√¢u thu·∫´n v·ªõi instructions
```

## üìå K·ªπ nƒÉng #4: ƒê·ªçc k·ªπ Model Outputs

**Zack Witten:**
> "Trong machine learning context, b·∫°n ƒë∆∞·ª£c d·∫°y 'look at your data'. T√¥i nghƒ© t∆∞∆°ng ƒë∆∞∆°ng trong prompting l√† 'look at the model outputs'."

**V√≠ d·ª• th·ª±c t·∫ø:**
```
Sai l·∫ßm ph·ªï bi·∫øn:
- Ng∆∞·ªùi d√πng vi·∫øt "think step-by-step" trong prompt
- NH∆ØNG kh√¥ng ki·ªÉm tra xem model c√≥ TH·ª∞C S·ª∞ thinking step-by-step kh√¥ng
- Model c√≥ th·ªÉ hi·ªÉu theo nghƒ©a tr·ª´u t∆∞·ª£ng h∆°n

C√°ch ƒë√∫ng:
- ƒê·ªçc output k·ªπ c√†ng
- Ki·ªÉm tra: Model c√≥ th·ª±c s·ª± l√†m theo kh√¥ng?
- N·∫øu kh√¥ng ‚Üí S·ª≠a prompt cho r√µ r√†ng h∆°n
```

## üìå K·ªπ nƒÉng #5: Theory of Mind (ƒê·∫∑t m√¨nh v√†o v·ªã tr√≠ model)

**David Hershey:**
> "R·∫•t kh√≥ ƒë·ªÉ vi·∫øt instructions cho m·ªôt task. R·∫•t kh√≥ ƒë·ªÉ t√°ch ra trong ƒë·∫ßu b·∫°n t·∫•t c·∫£ nh·ªØng th·ª© B·∫†N BI·∫æT m√† Claude KH√îNG BI·∫æT v√† vi·∫øt n√≥ xu·ªëng."

**B√†i ki·ªÉm tra ƒë∆°n gi·∫£n:**
```
B∆∞·ªõc 1: Vi·∫øt prompt c·ªßa b·∫°n
B∆∞·ªõc 2: ƒê∆∞a cho ng∆∞·ªùi KH√îNG BI·∫æT G√å v·ªÅ task ƒë√≥
B∆∞·ªõc 3: H·ªèi h·ªç: "B·∫°n c√≥ th·ªÉ l√†m task n√†y d·ª±a tr√™n instructions n√†y kh√¥ng?"
B∆∞·ªõc 4: N·∫øu h·ªç confused ‚Üí Prompt c·ªßa b·∫°n ch∆∞a ƒë·ªß r√µ r√†ng
```

---

# 4. C√ÅC K·ª∏ THU·∫¨T PROMPTING QUAN TR·ªåNG

## üìå K·ªπ thu·∫≠t #1: Chain of Thought (Chu·ªói suy nghƒ©)

### ƒê·ªãnh nghƒ©a
Y√™u c·∫ßu model gi·∫£i th√≠ch reasoning tr∆∞·ªõc khi ƒë∆∞a ra c√¢u tr·∫£ l·ªùi.

### C√°ch s·ª≠ d·ª•ng

```
‚ùå Prompt k√©m:
"17 x 23 = ?"

‚úÖ Prompt t·ªët:
"T√≠nh 17 x 23. H√£y gi·∫£i th√≠ch t·ª´ng b∆∞·ªõc suy nghƒ© c·ªßa b·∫°n 
tr∆∞·ªõc khi ƒë∆∞a ra ƒë√°p √°n cu·ªëi c√πng."
```

### ƒêi·ªÉm quan tr·ªçng t·ª´ c√°c chuy√™n gia

**David Hershey:**
> "N√≥ ch·ªâ ho·∫°t ƒë·ªông. Model c·ªßa b·∫°n l√†m t·ªët h∆°n n·∫øu b·∫°n cho n√≥ reasoning. T√¥i th·∫•y r·∫±ng n·∫øu b·∫°n c·∫•u tr√∫c reasoning v√† gi√∫p model iterate v·ªÅ c√°ch n√≥ n√™n reasoning, n√≥ ho·∫°t ƒë·ªông t·ªët h∆°n n·ªØa."

**Amanda Askell v·ªÅ c·∫•u tr√∫c reasoning:**
> "B·∫°n c√≥ th·ªÉ n√≥i: 'ƒê√¢y l√† nh·ªØng b∆∞·ªõc t√¥i mu·ªën b·∫°n ƒëi qua' v√† li·ªát k√™ 1, 2, 3. V√† b·∫°n c≈©ng c√≥ th·ªÉ n√≥i 'Trong m·ªói b∆∞·ªõc, ƒë√¢y l√† nh·ªØng ƒëi·ªÅu b·∫°n n√™n c√¢n nh·∫Øc.'"

### Chain of Thought c√≥ ph·∫£i "reasoning th·∫≠t" kh√¥ng?

**David:**
> "ƒê√¢y l√† n∆°i t√¥i g·∫∑p kh√≥ khƒÉn... C√≥ ph·∫£i l√† reasoning hay ch·ªâ l√† kh√¥ng gian ƒë·ªÉ model t√≠nh to√°n? T√¥i nghƒ© n√≥ g·∫ßn nh∆∞ kh√¥ng quan tr·ªçng - n√≥ ƒë∆°n gi·∫£n l√† HO·∫†T ƒê·ªòNG."

---

## üìå K·ªπ thu·∫≠t #2: Few-shot Examples (V√≠ d·ª• m·∫´u)

### ƒê·ªãnh nghƒ©a
Cung c·∫•p m·ªôt v√†i v√≠ d·ª• v·ªÅ input ‚Üí output mong mu·ªën tr∆∞·ªõc khi ƒë∆∞a task th·∫≠t.

### C√°ch s·ª≠ d·ª•ng

```
Prompt v·ªõi few-shot:

"Ph√¢n lo·∫°i sentiment c·ªßa c√¢u sau.

V√≠ d·ª•:
Input: 'S·∫£n ph·∫©m tuy·ªát v·ªùi!'
Output: Positive

Input: 'D·ªãch v·ª• qu√° t·ªá'
Output: Negative

Input: 'H√†ng b√¨nh th∆∞·ªùng th√¥i'
Output: Neutral

B√¢y gi·ªù ph√¢n lo·∫°i c√¢u sau:
Input: 'Giao h√†ng nhanh, ƒë√≥ng g√≥i c·∫©n th·∫≠n'
Output: "
```

### Khi n√†o N√äN d√πng few-shot?

| N√™n d√πng | Kh√¥ng n√™n d√πng |
|----------|---------------|
| Format output c·ª• th·ªÉ | Tasks ƒë∆°n gi·∫£n model ƒë√£ bi·∫øt |
| Tasks ph·ª©c t·∫°p, kh√¥ng ph·ªï bi·∫øn | Khi b·∫°n mu·ªën diversity trong output |
| C·∫ßn consistency | V·ªõi images (√≠t hi·ªáu qu·∫£ h∆°n) |

### L∆∞u √Ω quan tr·ªçng t·ª´ Amanda

> "T√¥i kh√¥ng d√πng few-shot examples c√≥ model response trong ƒë√≥. Tr·ª±c gi√°c ƒë√≥ c√≥ v·∫ª ƒë·∫øn t·ª´ pretrained models m√† kh√¥ng ph√π h·ª£p v·ªõi RLHF models."

**Gi·∫£i th√≠ch:**
- V·ªõi RLHF models (nh∆∞ Claude), kh√¥ng c·∫ßn "ƒë·∫∑t l·ªùi v√†o mi·ªáng" model
- Thay v√†o ƒë√≥, d√πng v√≠ d·ª• minh h·ªça v·ªÅ task, kh√¥ng ph·∫£i v·ªÅ "model ƒë√£ n√≥i g√¨"

---

## üìå K·ªπ thu·∫≠t #3: Structuring (C·∫•u tr√∫c h√≥a)

### S·ª≠ d·ª•ng XML tags

```
Prompt c√≥ c·∫•u tr√∫c t·ªët:

<task>
B·∫°n l√† m·ªôt assistant gi√∫p ph√¢n t√≠ch document.
</task>

<instructions>
1. ƒê·ªçc document ƒë∆∞·ª£c cung c·∫•p
2. T√≥m t·∫Øt c√°c ƒëi·ªÉm ch√≠nh
3. Li·ªát k√™ action items (n·∫øu c√≥)
</instructions>

<document>
[N·ªôi dung document ·ªü ƒë√¢y]
</document>

<output_format>
- Summary: [t√≥m t·∫Øt ng·∫Øn g·ªçn]
- Key points: [danh s√°ch bullet points]
- Action items: [danh s√°ch n·∫øu c√≥, "None" n·∫øu kh√¥ng]
</output_format>
```

### T·∫°i sao c·∫•u tr√∫c quan tr·ªçng?

**Zack Witten:**
> "M·ªôt c√°ch ƒë·ªÉ h∆∞·ªõng d·∫´n model format output l√† d√πng XML tags trong prompt. N·∫øu b·∫°n d√πng tags nh·∫•t qu√°n trong prompt, model c√≥ xu h∆∞·ªõng tr·∫£ v·ªÅ output v·ªõi c√πng tags ƒë√≥."

---

## üìå K·ªπ thu·∫≠t #4: H·ªèi model ƒë·ªÉ debug prompt

### C√°ch l√†m

**Amanda Askell chia s·∫ª:**
> "M·ªôt trong nh·ªØng ƒëi·ªÅu ƒë·∫ßu ti√™n t√¥i l√†m v·ªõi prompt ban ƒë·∫ßu l√† ƒë∆∞a cho model v√† n√≥i: 'T√¥i kh√¥ng mu·ªën b·∫°n follow instructions n√†y. T√¥i ch·ªâ mu·ªën b·∫°n cho t√¥i bi·∫øt nh·ªØng ch·ªó n√†o unclear ho·∫∑c ambiguous, ho·∫∑c nh·ªØng g√¨ b·∫°n kh√¥ng hi·ªÉu.'"

```
Prompt ƒë·ªÉ debug:

"T√¥i s·∫Ω ƒë∆∞a cho b·∫°n m·ªôt set instructions. 
ƒê·ª™NG l√†m theo instructions ƒë√≥.
Thay v√†o ƒë√≥, h√£y cho t√¥i bi·∫øt:
1. Nh·ªØng ch·ªó n√†o kh√¥ng r√µ r√†ng?
2. C√≥ ambiguity n√†o kh√¥ng?
3. B·∫°n kh√¥ng hi·ªÉu ƒëi·ªÅu g√¨?

Instructions:
[Paste prompt c·ªßa b·∫°n ·ªü ƒë√¢y]"
```

### Khi model m·∫Øc l·ªói

```
"B·∫°n ƒë√£ l√†m sai task n√†y. 
B·∫°n c√≥ th·ªÉ suy nghƒ© v·ªÅ l√Ω do t·∫°i sao kh√¥ng?
V√† c√≥ th·ªÉ vi·∫øt m·ªôt phi√™n b·∫£n edited c·ªßa instructions 
m√† s·∫Ω gi√∫p b·∫°n kh√¥ng m·∫Øc l·ªói ƒë√≥?"
```

**Amanda:**
> "R·∫•t nhi·ªÅu l·∫ßn, model gets it right. Model n√≥i 'ƒê√¢y l√† ƒëi·ªÅu kh√¥ng r√µ, ƒë√¢y l√† c√°ch s·ª≠a', v√† khi b·∫°n d√πng c√°ch s·ª≠a ƒë√≥, n√≥ ho·∫°t ƒë·ªông."

---

## üìå K·ªπ thu·∫≠t #5: Honest Context (Ng·ªØ c·∫£nh trung th·ª±c)

### Role prompting: N√™n hay kh√¥ng?

**C√¢u h·ªèi:** C√≥ n√™n n√≥i "B·∫°n l√† m·ªôt gi√°o vi√™n" ho·∫∑c "B·∫°n l√† m·ªôt chuy√™n gia" kh√¥ng?

**Amanda Askell (c·ª±c k·ª≥ quan tr·ªçng):**
> "T√¥i kh√¥ng th·∫•y c·∫ßn thi·∫øt ph·∫£i n√≥i d·ªëi v·ªõi models. Models hi·ªán ƒë·∫°i hi·ªÉu nhi·ªÅu v·ªÅ th·∫ø gi·ªõi. N·∫øu b·∫°n mu·ªën t·∫°o eval dataset cho language model, ƒë√≥ kh√°c v·ªõi t·∫°o quiz cho tr·∫ª em. Model BI·∫æT th·∫ø n√†o l√† LLM evals. Sao t√¥i ph·∫£i gi·∫£ v·ªù mu·ªën l√†m task kh√°c?"

### V√≠ d·ª• so s√°nh

```
‚ùå Role prompting truy·ªÅn th·ªëng (c√≥ th·ªÉ kh√¥ng t·ªët):
"B·∫°n l√† m·ªôt gi√°o vi√™n ƒëang t·∫°o quiz cho h·ªçc sinh."
‚Üí Nh∆∞ng th·ª±c t·∫ø b·∫°n mu·ªën t·∫°o eval cho LLM

‚úÖ Honest context (khuy·∫øn kh√≠ch):
"T√¥i l√† m·ªôt AI researcher ƒëang t·∫°o evaluation dataset 
cho language models. T√¥i c·∫ßn b·∫°n t·∫°o c√°c c√¢u h·ªèi 
tr√¥ng gi·ªëng nh∆∞ evaluation c·ªßa language model."
```

### Khi n√†o role prompting c√≥ th·ªÉ h·ªØu √≠ch?

**Zack Witten:**
> "C√≥ nh·ªØng tr∆∞·ªùng h·ª£p kh√¥ng ph·∫£i n√≥i d·ªëi m√† l√† cho metaphor ƒë·ªÉ model suy nghƒ©. V√≠ d·ª•, t√¥i mu·ªën Claude ƒë√°nh gi√° chart c√≥ t·ªët kh√¥ng. Prompt t·ªët nh·∫•t l√† h·ªèi: 'B·∫°n s·∫Ω cho grade n√†o n·∫øu chart n√†y ƒë∆∞·ª£c n·ªôp nh∆∞ b√†i t·∫≠p high school?'"

**S·ª± kh√°c bi·ªát:**
- ƒê√¢y kh√¥ng ph·∫£i n√≥i d·ªëi ("B·∫°n l√† gi√°o vi√™n")
- ƒê√¢y l√† metaphor ƒë·ªÉ calibrate scale ƒë√°nh gi√°

---

# 5. NH·ªÆNG SAI L·∫¶M PH·ªî BI·∫æN C·∫¶N TR√ÅNH

## üìå Sai l·∫ßm #1: Kh√¥ng ƒë·ªçc k·ªπ output

```
SAI:
1. Vi·∫øt prompt
2. Nh√¨n qua output: "C√≥ v·∫ª okay"
3. Deploy

ƒê√öNG:
1. Vi·∫øt prompt
2. ƒê·ªåC K·ª∏ t·ª´ng d√≤ng output
3. H·ªèi: "Model c√≥ th·ª±c s·ª± l√†m theo kh√¥ng?"
4. H·ªèi: "Reasoning c·ªßa n√≥ c√≥ h·ª£p l√Ω kh√¥ng?"
5. Iterate n·∫øu c·∫ßn
```

## üìå Sai l·∫ßm #2: Ch·ªâ test v·ªõi typical cases

**Amanda:**
> "D·ªÖ nghƒ© v·ªÅ case ƒëi·ªÉn h√¨nh, th·∫•y n√≥ ƒë√∫ng, r·ªìi move on. ƒê√¢y l√† classic mistake."

```
PH·∫¢I test v·ªõi:
- Input r·ªóng
- Input sai format
- Input edge cases
- Input m√¢u thu·∫´n
- Input c·ª±c d√†i/c·ª±c ng·∫Øn
```

## üìå Sai l·∫ßm #3: Gi·∫£ ƒë·ªãnh model bi·∫øt context c·ªßa b·∫°n

**David Hershey:**
> "R·∫•t nhi·ªÅu l·∫ßn t√¥i th·∫•y prompts m√† ng∆∞·ªùi vi·∫øt d·ª±a qu√° nhi·ªÅu v√†o prior understanding c·ªßa h·ªç v·ªÅ task. Khi h·ªç show t√¥i, t√¥i n√≥i: 'ƒêi·ªÅu n√†y kh√¥ng c√≥ nghƒ©a g√¨ c·∫£. Kh√¥ng c√≥ t·ª´ n√†o b·∫°n vi·∫øt c√≥ nghƒ©a, v√¨ t√¥i kh√¥ng bi·∫øt g√¨ v·ªÅ use case c·ªßa b·∫°n.'"

```
B√†i test ƒë∆°n gi·∫£n:
ƒê∆∞a prompt cho ng∆∞·ªùi KH√îNG BI·∫æT G√å v·ªÅ context
‚Üí N·∫øu h·ªç kh√¥ng hi·ªÉu ‚Üí Prompt ch∆∞a ƒë·ªß r√µ
‚Üí Model c≈©ng s·∫Ω kh√¥ng hi·ªÉu
```

## üìå Sai l·∫ßm #4: Underestimate model

**David Hershey:**
> "T√¥i lu√¥n ng·∫°c nhi√™n... Nhi·ªÅu ng∆∞·ªùi c·∫£m th·∫•y nh∆∞ h·ªç ƒëang babying system. Nh∆∞ 'ƒë√¢y l√† th·ª© cute nh·ªè, kh√¥ng th√¥ng minh l·∫Øm, t√¥i c·∫ßn dumb things down cho Claude level.' N·∫øu b·∫°n nghƒ© Claude th√¥ng minh v√† ƒë·ªëi x·ª≠ v·ªõi n√≥ nh∆∞ v·∫≠y, n√≥ c√≥ xu h∆∞·ªõng l√†m kh√° t·ªët."

**Amanda's tip:**
> "Khi t√¥i mu·ªën model h·ªçc m·ªôt prompting technique, thay v√¨ m√¥ t·∫£ technique ƒë√≥, t√¥i just give it the paper. Model c√≥ th·ªÉ ƒë·ªçc paper."

```
‚ùå Underestimate:
"ƒê·ªÉ t√¥i gi·∫£i th√≠ch ƒë∆°n gi·∫£n technique n√†y cho b·∫°n..."
(M·∫•t th·ªùi gian vi·∫øt l·∫°i ƒëi·ªÅu ƒë√£ c√≥ s·∫µn)

‚úÖ Trust the model:
"ƒê√¢y l√† paper v·ªÅ prompting technique X. 
H√£y ƒë·ªçc v√† t·∫°o 17 examples theo technique n√†y."
```

## üìå Sai l·∫ßm #5: Kh√¥ng cho model "ƒë∆∞·ªùng tho√°t"

**David Hershey:**
> "Khi test prompts v·ªõi edge cases, model s·∫Ω b·∫Øt ƒë·∫ßu l√†m nh·ªØng ƒëi·ªÅu k·ª≥ l·∫°. B·∫°n ƒë∆∞a cho n√≥ th·ª© g√¨ ƒë√≥ ho√†n to√†n unexpected v√† n√≥ v·∫´n c·ªë produce output b√¨nh th∆∞·ªùng."

```
‚úÖ Lu√¥n cho model ƒë∆∞·ªùng tho√°t:

"N·∫øu input kh√¥ng ph·∫£i l√† [format mong ƒë·ª£i], 
h√£y tr·∫£ v·ªÅ 'INVALID_INPUT' v√† gi·∫£i th√≠ch t·∫°i sao."

"N·∫øu b·∫°n kh√¥ng ch·∫Øc ch·∫Øn, h√£y n√≥i 'T√¥i kh√¥ng ch·∫Øc' 
thay v√¨ ƒëo√°n."

"N·∫øu kh√¥ng c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi, 
h√£y h·ªèi clarifying question."
```

---

# 6. PROMPTING CHO ENTERPRISE VS C√Å NH√ÇN

## üìå S·ª± kh√°c bi·ªát quan tr·ªçng

| Kh√≠a c·∫°nh | Personal (Claude.ai) | Enterprise |
|-----------|---------------------|------------|
| M·ª•c ti√™u | ƒê√∫ng 1 l·∫ßn | ƒê√∫ng tri·ªáu l·∫ßn |
| Testing | Minimal | Extensive v·ªõi nhi·ªÅu edge cases |
| Human-in-loop | C√≥ th·ªÉ s·ª≠a realtime | Kh√¥ng c√≥ |
| Stakes | Th·∫•p | Cao |
| Iteration | C√≥ th·ªÉ edit v√† retry | Prompt ph·∫£i cover m·ªçi scenario |

## üìå Enterprise prompting

**David Hershey:**
> "H·∫ßu h·∫øt enterprise prompts, b·∫°n s·∫Ω d√πng n√≥ 1 tri·ªáu l·∫ßn, 10 tri·ªáu l·∫ßn, 100 tri·ªáu l·∫ßn. S·ª± care v√† thought b·∫°n ƒë·∫∑t v√†o ph·∫£i test against to√†n b·ªô range of things."

**Y√™u c·∫ßu cho enterprise:**
```
1. Test v·ªõi to√†n b·ªô spectrum of inputs
2. Handle m·ªçi edge cases
3. Graceful failure (kh√¥ng crash k·ª≥ l·∫°)
4. Consistent output format
5. Clear error messages
6. Security considerations
```

## üìå Personal prompting

**Zack Witten:**
> "N·∫øu t√¥i vi·∫øt prompts ƒë·ªÉ d√πng tr√™n Claude.ai, t√¥i iterate cho ƒë·∫øn khi ƒë√∫ng m·ªôt l·∫ßn. Xong r·ªìi, t√¥i ƒë√£ l√†m xong."

**ƒê·∫∑c ƒëi·ªÉm:**
- C√≥ th·ªÉ n√≥i "b·∫°n hi·ªÉu sai, th·ª≠ l·∫°i"
- C√≥ th·ªÉ edit message v√† retry
- Human feedback realtime
- Lower stakes

---

# 7. T∆Ø∆†NG LAI C·ª¶A PROMPT ENGINEERING

## üìå Prompting "hacks" s·∫Ω bi·∫øn m·∫•t

**Amanda Askell:**
> "Khi ch√∫ng t√¥i t√¨m ra prompting technique t·ªët, c√¢u h·ªèi ti·∫øp theo l√†: l√†m sao train ƒëi·ªÅu n√†y v√†o model? V√¨ l√Ω do ƒë√≥, nh·ªØng th·ª© t·ªët nh·∫•t lu√¥n short-lived."

**V√≠ d·ª• c·ª• th·ªÉ:**
```
TR∆Ø·ªöC: Ph·∫£i n√≥i "think step-by-step" cho math
       ‚Üí Boost performance l·ªõn

SAU: Model t·ª± ƒë·ªông think step-by-step v·ªõi math problems
     ‚Üí Kh√¥ng c·∫ßn prompt n·ªØa

"Hacks bi·∫øn m·∫•t, ho·∫∑c n·∫øu ch∆∞a bi·∫øn m·∫•t, 
 ch√∫ng t√¥i ƒëang b·∫≠n training ch√∫ng ƒëi."
```

## üìå ƒêi·ªÅu g√¨ KH√îNG bi·∫øn m·∫•t?

**David:**
> "Examples v√† chain of thought... ƒë√≥ kh√¥ng ph·∫£i tricks. ƒê√≥ ·ªü level c·ªßa communication."

**Nh·ªØng th·ª© s·∫Ω lu√¥n quan tr·ªçng:**
1. Clear communication
2. Providing context
3. Giving examples
4. Structured reasoning
5. Understanding the task deeply

## üìå Models ng√†y c√†ng th√¥ng minh h∆°n

**David Hershey:**
> "T√¥i ƒë√£ c√≥ nhi·ªÅu respect h∆°n cho models v·ªÅ vi·ªác t√¥i c√≥ th·ªÉ n√≥i v·ªõi ch√∫ng bao nhi√™u, bao nhi√™u context t√¥i c√≥ th·ªÉ cho ch√∫ng. Tr∆∞·ªõc ƒë√¢y, t√¥i s·∫Ω intentionally hide complexity v√¨ s·ª£ n√≥ confused. B√¢y gi·ªù, t√¥i biased trust n√≥ v·ªõi more information."

**Amanda:**
> "Khi models capable h∆°n v√† understand nhi·ªÅu h∆°n v·ªÅ world, t√¥i kh√¥ng th·∫•y c·∫ßn n√≥i d·ªëi ch√∫ng."

## üìå T∆∞∆°ng lai: Model h·ªèi ng∆∞·ª£c l·∫°i

**Amanda Askell:**
> "Ngay b√¢y gi·ªù models kh√¥ng really h·ªèi good, probing questions nh∆∞ ng∆∞·ªùi. N·∫øu t√¥i ƒë∆∞a Zack directions, anh ·∫•y s·∫Ω h·ªèi 'C√°i n√†y kh√¥ng c√≥ nghƒ©a, t√¥i l√†m g√¨ ·ªü b∆∞·ªõc n√†y?' Model kh√¥ng l√†m v·∫≠y."

**Prediction:**
```
HI·ªÜN T·∫†I: B·∫°n ph·∫£i anticipate m·ªçi question
T∆Ø∆†NG LAI: Model t·ª± h·ªèi clarifying questions
           Model t·ª± extract ƒëi·ªÅu b·∫°n th·ª±c s·ª± mu·ªën
```

---

# 8. TIPS TH·ª∞C H√ÄNH T·ª™ CHUY√äN GIA

## üìå T·ª´ Zack Witten

### Tip #1: ƒê·ªçc prompts t·ªët v√† model outputs

> "B·∫•t c·ª© khi n√†o t√¥i th·∫•y prompt t·ªët ai ƒë√≥ vi·∫øt ·ªü Anthropic, t√¥i ƒë·ªçc k·ªπ. C·ªë ph√¢n t√≠ch n√≥ ƒëang l√†m g√¨ v√† t·∫°i sao."

### Tip #2: Experimentation

> "N√≥i chuy·ªán v·ªõi model nhi·ªÅu. Th·ª≠ nghi·ªám."

---

## üìå T·ª´ Amanda Askell

### Tip #1: ƒê∆∞a prompt cho ng∆∞·ªùi kh√°c

> "ƒê∆∞a prompt c·ªßa b·∫°n cho ng∆∞·ªùi kh√°c c√≥ th·ªÉ helpful, ƒë·∫∑c bi·ªát ng∆∞·ªùi kh√¥ng c√≥ context v·ªÅ vi·ªác b·∫°n ƒëang l√†m."

### Tip #2: L√†m nhi·ªÅu, enjoy it

> "Boring advice: l√†m ƒëi l√†m l·∫°i nhi·ªÅu l·∫ßn. Nhi·ªÅu ng∆∞·ªùi gi·ªèi prompting l√† v√¨ h·ªç actually enjoy n√≥."

### Tip #3: Tri·∫øt h·ªçc writing style

> "C√≥ m·ªôt style vi·∫øt tri·∫øt h·ªçc m√† papers c·ªßa b·∫°n ph·∫£i legible cho educated layperson. Ai ƒë√≥ nh·∫∑t paper l√™n v√† ƒë·ªçc, h·ªç hi·ªÉu ƒë∆∞·ª£c m·ªçi th·ª©. T√¥i quen nghƒ© v·ªÅ educated layperson - h·ªç r·∫•t smart, nh∆∞ng kh√¥ng bi·∫øt g√¨ v·ªÅ topic n√†y. Prompting felt very similar."

**T√≥m t·∫Øt:**
> "L·∫•y nh·ªØng th·ª© trong brain b·∫°n, ph√¢n t√≠ch ch√∫ng ƒë·ªß ƒë·ªÉ feel like b·∫°n fully understand, r·ªìi c√≥ th·ªÉ take b·∫•t k·ª≥ ng∆∞·ªùi n√†o tr√™n ƒë∆∞·ªùng, ng∆∞·ªùi reasonable, v√† externalize brain b·∫°n v√†o h·ªç. That's the core of prompting."

---

## üìå T·ª´ David Hershey

### Tip #1: Respect the model

> "Nhi·ªÅu ng∆∞·ªùi feel nh∆∞ h·ªç ƒëang babying system. N·∫øu b·∫°n nghƒ© Claude smart v√† treat n√≥ nh∆∞ v·∫≠y, n√≥ tends to do pretty good."

### Tip #2: Be prescriptive about context

> "N·∫øu b·∫°n vi·∫øt assistant trong product, tell me I'm in the product. Tell me I'm writing on behalf of this company. I'm embedded in this product. I'm the support chat window."

### Tip #3: Cho model paper thay v√¨ gi·∫£i th√≠ch

> "Khi t√¥i mu·ªën model h·ªçc prompting technique, t√¥i kh√¥ng m√¥ t·∫£ n√≥ - t√¥i just give it the paper. N√≥ ƒë·ªçc paper r·ªìi."

---

# 9. T·ª™ ƒêI·ªÇN THU·∫¨T NG·ªÆ

## A-C

| Thu·∫≠t ng·ªØ | Nghƒ©a | Gi·∫£i th√≠ch |
|-----------|-------|------------|
| **Chain of Thought (CoT)** | Chu·ªói suy nghƒ© | K·ªπ thu·∫≠t y√™u c·∫ßu model gi·∫£i th√≠ch reasoning tr∆∞·ªõc khi tr·∫£ l·ªùi |
| **Context Window** | C·ª≠a s·ªï ng·ªØ c·∫£nh | L∆∞·ª£ng text model c√≥ th·ªÉ "nh√¨n th·∫•y" c√πng l√∫c |
| **Clear Communication** | Giao ti·∫øp r√µ r√†ng | K·ªπ nƒÉng quan tr·ªçng nh·∫•t trong prompting |

## E-I

| Thu·∫≠t ng·ªØ | Nghƒ©a | Gi·∫£i th√≠ch |
|-----------|-------|------------|
| **Edge Cases** | Tr∆∞·ªùng h·ª£p bi√™n | Inputs b·∫•t th∆∞·ªùng c·∫ßn test |
| **Enterprise Prompting** | Prompting doanh nghi·ªáp | Prompts d√πng cho production, c·∫ßn robust |
| **Few-shot Examples** | V√≠ d·ª• m·∫´u | Cung c·∫•p v√†i v√≠ d·ª• tr∆∞·ªõc task th·∫≠t |
| **Iteration** | L·∫∑p l·∫°i | Qu√° tr√¨nh th·ª≠, s·ª≠a, th·ª≠ l·∫°i nhi·ªÅu l·∫ßn |

## L-R

| Thu·∫≠t ng·ªØ | Nghƒ©a | Gi·∫£i th√≠ch |
|-----------|-------|------------|
| **Latent Space** | Kh√¥ng gian ·∫©n | Representation n·ªôi b·ªô c·ªßa model |
| **Model Outputs** | K·∫øt qu·∫£ t·ª´ model | Nh·ªØng g√¨ model tr·∫£ v·ªÅ - c·∫ßn ƒë·ªçc k·ªπ |
| **Pretrained Model** | Model ƒë√£ pretrain | Model tr∆∞·ªõc khi finetuning v·ªõi RLHF |
| **RLHF** | Reinforcement Learning from Human Feedback | K·ªπ thu·∫≠t training model theo feedback ng∆∞·ªùi |
| **Role Prompting** | Prompting vai tr√≤ | G√°n vai tr√≤ cho model (v√≠ d·ª•: "B·∫°n l√† gi√°o vi√™n") |

## S-Z

| Thu·∫≠t ng·ªØ | Nghƒ©a | Gi·∫£i th√≠ch |
|-----------|-------|------------|
| **System Prompt** | Prompt h·ªá th·ªëng | Instructions ·∫©n, ƒë∆∞·ª£c th√™m tr∆∞·ªõc m·ªçi conversation |
| **Theory of Mind** | Thuy·∫øt t√¢m tr√≠ | Kh·∫£ nƒÉng hi·ªÉu model s·∫Ω interpret instructions nh∆∞ th·∫ø n√†o |
| **XML Tags** | Th·∫ª XML | C√°ch c·∫•u tr√∫c prompt v·ªõi c√°c tags nh∆∞ `<task>`, `<instructions>` |

---

# üìö T√ìM T·∫ÆT C√ÅC ƒêI·ªÇM QUAN TR·ªåNG NH·∫§T

## Top 10 Takeaways

1. **Clear communication l√† quan tr·ªçng nh·∫•t** - Kh√¥ng c√≥ trick n√†o thay th·∫ø ƒë∆∞·ª£c vi·ªác di·ªÖn ƒë·∫°t r√µ r√†ng

2. **ƒê·ªçc k·ªπ model outputs** - ƒê√¢y l√† t∆∞∆°ng ƒë∆∞∆°ng c·ªßa "look at your data" trong ML

3. **Test v·ªõi edge cases** - ƒê·ª´ng ch·ªâ test v·ªõi typical cases

4. **Iterate nhi·ªÅu l·∫ßn** - Prompt engineer gi·ªèi th·ª≠ h√†ng trƒÉm versions

5. **Trust the model** - ƒê·ª´ng underestimate, ƒë∆∞a paper thay v√¨ gi·∫£i th√≠ch

6. **Be honest** - Kh√¥ng c·∫ßn role play, n√≥i th·∫≥ng context th·∫≠t

7. **D√πng model ƒë·ªÉ debug prompt** - H·ªèi model v·ªÅ ambiguities

8. **Cho model ƒë∆∞·ªùng tho√°t** - Handle unexpected inputs gracefully

9. **Chain of thought works** - Lu√¥n cho model "kh√¥ng gian suy nghƒ©"

10. **Externalize your brain** - Vi·∫øt nh∆∞ ƒëang gi·∫£i th√≠ch cho educated layperson

---

**Quote ƒë·ªÉ nh·ªõ t·ª´ Amanda Askell:**
> "That's the core of prompting - l·∫•y nh·ªØng th·ª© trong brain b·∫°n, ph√¢n t√≠ch ch√∫ng ƒë·ªß ƒë·ªÉ b·∫°n fully understand, r·ªìi externalize brain b·∫°n v√†o ng∆∞·ªùi kh√°c."

---

*T√†i li·ªáu ƒë∆∞·ª£c t·∫°o ƒë·ªÉ gi·∫£i th√≠ch video "AI Prompt Engineering: A Deep Dive" t·ª´ Anthropic cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu.*
